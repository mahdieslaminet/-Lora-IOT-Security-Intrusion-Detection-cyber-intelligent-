{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d63bc3db",
      "metadata": {},
      "source": [
        "# IoT Traffic Anomaly Detection Reproduction\n",
        "\n",
        "This notebook reproduces the workflow from Vigoya et al. (Electronics 2021) using proxy IoT/SCADA datasets. It mirrors the paper's preprocessing (cyclical time encoding, binning, one-hot encoding, flow aggregation), nested CV with SMOTE, RFE feature selection, and evaluation of five shallow ML models. Optional sections include extended models and threat-intel similarity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c068ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "from iot_anomaly_detection.data import load_hf_dataset\n",
        "from iot_anomaly_detection.data.feature_mapping import infer_feature_mapping, apply_feature_mapping\n",
        "from iot_anomaly_detection.data.preprocessing import FeaturePreprocessor\n",
        "from iot_anomaly_detection.models import (\n",
        "    LogisticRegressionDetector,\n",
        "    BernoulliNBDetector,\n",
        "    RandomForestDetector,\n",
        "    AdaBoostDetector,\n",
        "    LinearSVMDetector,\n",
        "    ExtraTreesDetector,\n",
        "    GradientBoostingDetector,\n",
        "    nested_cv_evaluate,\n",
        ")\n",
        "from iot_anomaly_detection.utils.cv import build_nested_cv\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "OUTPUT_DIR = Path(\"notebooks/outputs\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4865cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config: select dataset and sample size.\n",
        "dataset_name = \"vossmoos/vestasv52-scada-windturbine-granada\"\n",
        "sample_size = 5000\n",
        "random_state = 42\n",
        "rfe_features = 10\n",
        "use_extra_models = False\n",
        "run_threat_intel = False\n",
        "\n",
        "# Other available datasets:\n",
        "# - \"fenar/iot-security\"\n",
        "# - \"schooly/Cyber-Security-Breaches\"\n",
        "# - \"stu8king/securityincidents\"\n",
        "# - \"kutay1907/scadaphotodataset\"\n",
        "# - \"kutay1907/ScadaData100k\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9bb4e28",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a proxy dataset from Hugging Face.\n",
        "df = load_hf_dataset(dataset_name, split=\"train\", sample_size=sample_size)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6dc070b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Infer and inspect feature mapping against the core attributes.\n",
        "mapping = infer_feature_mapping(df.columns)\n",
        "mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1a4a71",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build labels and show class balance after mapping.\n",
        "mapped = apply_feature_mapping(df, mapping)\n",
        "label_counts = mapped[\"label\"].value_counts()\n",
        "label_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842b3cb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot label distribution.\n",
        "plt.figure(figsize=(4, 3))\n",
        "sns.barplot(x=label_counts.index.astype(str), y=label_counts.values, palette=\"viridis\")\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"label_distribution.png\", dpi=200)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3caf80d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate accuracy vs number of features selected by RFE for a baseline model.\n",
        "feature_counts = [5, 8, 10, 12, 14]\n",
        "X = df\n",
        "y = mapped[\"label\"]\n",
        "\n",
        "acc_means = []\n",
        "for k in feature_counts:\n",
        "    preprocessor = FeaturePreprocessor(mapping=mapping)\n",
        "    summary, _, _, _ = nested_cv_evaluate(\n",
        "        X,\n",
        "        y,\n",
        "        LogisticRegressionDetector(),\n",
        "        preprocessor,\n",
        "        rfe_features=k,\n",
        "    )\n",
        "    acc_means.append(summary[\"accuracy\"][\"mean\"])\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(feature_counts, acc_means, marker=\"o\")\n",
        "plt.title(\"Accuracy vs Selected Features (RFE)\")\n",
        "plt.xlabel(\"Number of Features\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"accuracy_vs_features.png\", dpi=200)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d00818",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate the five shallow models with nested CV.\n",
        "models = [\n",
        "    LogisticRegressionDetector(),\n",
        "    BernoulliNBDetector(),\n",
        "    RandomForestDetector(),\n",
        "    AdaBoostDetector(),\n",
        "    LinearSVMDetector(),\n",
        "]\n",
        "\n",
        "if use_extra_models:\n",
        "    models += [ExtraTreesDetector(), GradientBoostingDetector()]\n",
        "\n",
        "leaderboard_rows = []\n",
        "model_results = {}\n",
        "\n",
        "for model in models:\n",
        "    preprocessor = FeaturePreprocessor(mapping=mapping)\n",
        "    summary, _, _, fold_predictions = nested_cv_evaluate(\n",
        "        X,\n",
        "        y,\n",
        "        model,\n",
        "        preprocessor,\n",
        "        rfe_features=rfe_features,\n",
        "    )\n",
        "    model_results[model.name] = {\"summary\": summary, \"fold_predictions\": fold_predictions}\n",
        "    leaderboard_rows.append({\n",
        "        \"model\": model.name,\n",
        "        \"accuracy_mean\": summary[\"accuracy\"][\"mean\"],\n",
        "        \"accuracy_std\": summary[\"accuracy\"][\"std\"],\n",
        "        \"precision_mean\": summary[\"precision\"][\"mean\"],\n",
        "        \"precision_std\": summary[\"precision\"][\"std\"],\n",
        "        \"recall_mean\": summary[\"recall\"][\"mean\"],\n",
        "        \"recall_std\": summary[\"recall\"][\"std\"],\n",
        "        \"f1_mean\": summary[\"f1\"][\"mean\"],\n",
        "        \"f1_std\": summary[\"f1\"][\"std\"],\n",
        "    })\n",
        "\n",
        "leaderboard = pd.DataFrame(leaderboard_rows).sort_values(by=\"f1_mean\", ascending=False)\n",
        "leaderboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43edc069",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save leaderboard table as an image.\n",
        "fig, ax = plt.subplots(figsize=(8, 0.5 + 0.4 * len(leaderboard)))\n",
        "ax.axis(\"off\")\n",
        "table = ax.table(\n",
        "    cellText=np.round(leaderboard.drop(columns=[\"model\"]).values, 3),\n",
        "    colLabels=leaderboard.drop(columns=[\"model\"]).columns,\n",
        "    rowLabels=leaderboard[\"model\"],\n",
        "    loc=\"center\",\n",
        ")\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(8)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"leaderboard_table.png\", dpi=200)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6029fec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot model comparison (Accuracy, Precision, Recall, F1).\n",
        "metrics = [\"accuracy_mean\", \"precision_mean\", \"recall_mean\", \"f1_mean\"]\n",
        "melted = leaderboard.melt(id_vars=[\"model\"], value_vars=metrics, var_name=\"metric\", value_name=\"score\")\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(data=melted, x=\"model\", y=\"score\", hue=\"metric\")\n",
        "plt.title(\"Model Comparison (Mean Metrics)\")\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"model_comparison.png\", dpi=200)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f2a091",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nested CV with ROC curves and validation AUC (inner CV).\n",
        "def nested_cv_scores(X, y, model, mapping, rfe_features=10, random_state=42):\n",
        "    outer_cv, inner_cv = build_nested_cv(random_state=random_state)\n",
        "    y_true_all = []\n",
        "    y_score_all = []\n",
        "    inner_scores = []\n",
        "\n",
        "    param_grid = {f\"model__{k}\": v for k, v in model.get_search_space().items()}\n",
        "\n",
        "    for train_idx, test_idx in outer_cv.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        preprocessor = FeaturePreprocessor(mapping=mapping)\n",
        "        pipeline = Pipeline(\n",
        "            steps=[\n",
        "                (\"preprocess\", preprocessor),\n",
        "                (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"smote\", SMOTE(random_state=random_state)),\n",
        "                (\"rfe\", RFE(estimator=DecisionTreeClassifier(random_state=random_state), n_features_to_select=rfe_features, step=0.1)),\n",
        "                (\"model\", model.build_estimator(model.get_default_params())),\n",
        "            ]\n",
        "        )\n",
        "        search = GridSearchCV(pipeline, param_grid=param_grid, cv=inner_cv, scoring=\"roc_auc\", n_jobs=-1)\n",
        "        search.fit(X_train, y_train)\n",
        "        inner_scores.append(search.best_score_)\n",
        "        best_model = search.best_estimator_\n",
        "\n",
        "        if hasattr(best_model, \"predict_proba\"):\n",
        "            y_score = best_model.predict_proba(X_test)[:, 1]\n",
        "        elif hasattr(best_model, \"decision_function\"):\n",
        "            y_score = best_model.decision_function(X_test)\n",
        "        else:\n",
        "            y_score = best_model.predict(X_test)\n",
        "        y_true_all.append(y_test.to_numpy())\n",
        "        y_score_all.append(np.asarray(y_score))\n",
        "\n",
        "    return np.concatenate(y_true_all), np.concatenate(y_score_all), inner_scores\n",
        "\n",
        "roc_records = []\n",
        "validation_records = []\n",
        "plt.figure(figsize=(7, 5))\n",
        "for model in models:\n",
        "    y_true_all, y_score_all, inner_scores = nested_cv_scores(X, y, model, mapping, rfe_features=rfe_features)\n",
        "    fpr, tpr, _ = roc_curve(y_true_all, y_score_all)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    roc_records.append({\"model\": model.name, \"roc_auc\": roc_auc})\n",
        "    validation_records.append({\"model\": model.name, \"val_auc_mean\": np.mean(inner_scores), \"val_auc_std\": np.std(inner_scores, ddof=1)})\n",
        "    plt.plot(fpr, tpr, label=f\"{model.name} (AUC={roc_auc:.3f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves (Nested CV)\")\n",
        "plt.legend(fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"roc_curves.png\", dpi=200)\n",
        "plt.show()\n",
        "\n",
        "validation_df = pd.DataFrame(validation_records)\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.bar(validation_df[\"model\"], validation_df[\"val_auc_mean\"], yerr=validation_df[\"val_auc_std\"], capsize=4)\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "plt.ylabel(\"Validation ROC AUC (mean Â± std)\")\n",
        "plt.title(\"Inner CV Validation Performance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"validation_auc.png\", dpi=200)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2494464",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- If your dataset has missing fields, the mapper simulates required attributes (protocol, ports, timestamps) so the pipeline can run end-to-end.\n",
        "- Expect tree-based models (Random Forest, AdaBoost) to outperform linear baselines, aligning with the paper's findings.\n",
        "- Charts are saved to `notebooks/outputs/` for easy inclusion in reports.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
